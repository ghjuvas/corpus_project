{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отзывы на фильм \"Железный человек 3\"\n",
    "Для работы я выбрала рецензии на этот фильм, потому что, как известно, чем дальше фильм, тем ниже рейтинг. При этом ЖЧ-3 достаточно популярен, чтобы набрать побольше рецензий. Более того, в данном случае легко набрать рецензий для проверки - в качестве них я беру рецензии на ЖЧ-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import requests, re, nltk\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "import collections\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем ссылки на все рецензии (положительные и отрицательные, из разных ссылок их проще выкачивать). При этом дальше мы функциями обкачиваем ссылки и чистим их от лишних вещей.\n",
    "\n",
    "###### Важно, что плохие отзывы мы ещё чистим от отзывов, оценка за которые 6 или выше, потому что это может оказаться слишком \"нейтральными\". Дисбаланс между количеством положительных и отрицательных отзывов компенсируем за счёт ограничения количества отзывов, которое мы берём на уровне фильтрации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_revs_link = 'https://www.kinopoisk.ru/film/462762/reviews/ord/rating/status/bad/perpage/100/'\n",
    "good_revs_link = 'https://www.kinopoisk.ru/film/462762/reviews/ord/rating/status/good/perpage/100/'\n",
    "good_check_link = 'https://www.kinopoisk.ru/film/411924/reviews/ord/rating/status/good/perpage/50/'\n",
    "bad_check_link = 'https://www.kinopoisk.ru/film/411924/reviews/ord/rating/status/bad/perpage/50/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(link):\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    html = soup.find_all('span', {'itemprop': 'reviewBody'})\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bad(reviews):\n",
    "    too_good = ['6 из 10', '7 из 10', '6.5 из 10', '7.5 из 10']\n",
    "    bad_revs = []\n",
    "    for rev in reviews:\n",
    "        for mark in too_good:\n",
    "            if mark in str(rev):\n",
    "                reviews.remove(rev)\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_revs(reviews, max_len):\n",
    "    filtered = []\n",
    "    reg = re.compile('<.*?>')\n",
    "    counter = 0\n",
    "    for rev in reviews:\n",
    "        if counter < max_len:\n",
    "            clean_rev = re.sub(reg, '', str(rev))\n",
    "            filtered.append(clean_rev)\n",
    "            counter = counter + 1\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_set(revs):\n",
    "    words = []\n",
    "    for rev in revs:\n",
    "        for word in nltk.word_tokenize(rev.lower()): \n",
    "            if word.isalpha():\n",
    "                lemma = morph.parse(word)[0].normal_form\n",
    "                words.append(lemma)\n",
    "    count = collections.Counter(words).most_common(1400)\n",
    "    return set(list(dict(count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После фильтрации и доставания множеств слов пишем функцию, которая будем с этими множествами опреедлять тональность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tone(review):\n",
    "    good_count = 0\n",
    "    bad_count = 0\n",
    "    result = str()\n",
    "    for word in nltk.word_tokenize(review):\n",
    "        if word.isalpha():\n",
    "            lemma = morph.parse(word)[0].normal_form\n",
    "            if lemma in full_bad_words:\n",
    "                bad_count += 1\n",
    "            elif lemma in full_good_words:\n",
    "                good_count += 1\n",
    "    if good_count > bad_count:\n",
    "        result = 'good'\n",
    "    elif bad_count >= good_count:\n",
    "        result = 'bad'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_reviews_raw = filter_bad(get_reviews(bad_revs_link))\n",
    "good_reviews_raw = get_reviews(good_revs_link)\n",
    "bad_check = filter_bad(get_reviews(bad_check_link))\n",
    "good_check = get_reviews(good_check_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_revs = filter_revs(bad_reviews_raw, len(bad_reviews_raw))\n",
    "good_revs = filter_revs(good_reviews_raw, len(bad_reviews_raw))\n",
    "good_check_revs = filter_revs(good_check, 25)\n",
    "bad_check_revs = filter_revs(bad_check, 25)\n",
    "full_bad_words = getting_set(bad_revs)\n",
    "full_good_words = getting_set(good_revs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_check = {'bad': bad_check_revs, 'good': good_check_revs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "double = []\n",
    "for word in full_bad_words:\n",
    "    if word in full_good_words:\n",
    "        double.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in double:\n",
    "    if d in full_bad_words:\n",
    "        full_bad_words.remove(d)\n",
    "    if d in full_good_words:\n",
    "        full_good_words.remove(d)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате код выдаёт точность программы. программу можно улучшить по-разному: например, можно было бы отсеивать из отрицательных отзывов еще и отзывы с 4-5 из 10, потому что такие отзывы бывают нейтральными + можно было бы отсеивать отзывы на 7-8 из 10 среди хороших. Было бы хорошо добавить больше данных: например, обкачать все фильмы марвел таким образом (если мыслить о близких отзывах). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность:  0.76\n"
     ]
    }
   ],
   "source": [
    "tones = ['bad', 'good']\n",
    "results = []\n",
    "gold = []\n",
    "for tone in tones:\n",
    "    for rev in for_check[tone]:\n",
    "        results.append(check_tone(rev))\n",
    "        gold.append(tone)\n",
    "print('Точность: ', accuracy_score(results, gold))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
